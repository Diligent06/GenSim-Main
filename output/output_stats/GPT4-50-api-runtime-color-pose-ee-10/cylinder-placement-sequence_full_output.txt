

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
Based on the provided assets and guidelines, here is a new task described in natural language:

Task Name: "cylinder-sort-stand"

Task Description: "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities."

Assets Used: ["zone/zone.urdf", "stacking/stand.urdf", "cylinder/cylinder-template.urdf"]

This task is novel because it combines elements of color matching with precision placement, which requires the robot to not only identify the correct color of the cylinder and stand but also to carefully position the cylinder onto the stand without knocking it over. The challenge stems from the precise manipulation needed to ensure the cylinder is balanced on the stand and the complexity of distinguishing between multiple colors.

The task in Python dictionary format would be:

```python
{
    "task-name": "cylinder-sort-stand",
    "task-description": "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.",
    "assets-used": ["zone/zone.urdf", "stacking/stand.urdf", "cylinder/cylinder-template.urdf"]
}
```

================= API Preview!

>>> Prompt: 
Before writing the code for the task "cylinder-sort-stand". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
I understand the provided APIs and their functionalities. Here's a summary of my understanding:

The `Task` class serves as a base class for defining robot simulation tasks. It initializes with default parameters for the end effector, mode, six degrees of freedom (DoF) flag, pick and place primitive, oracle cameras, evaluation thresholds, workspace bounds, and other task-related variables.

The `reset` method is called to reset the task environment, initializing goals, language goals, progress, and rewards.

The `oracle` method provides an oracle agent that can generate actions based on perfect knowledge of the environment. It uses segmentation masks and heightmaps to determine the best pick and place actions to achieve the task goals.

The `reward` method calculates the reward for the current timestep based on the task's goals and the current state of the environment. It uses different metrics such as 'pose' and 'zone' to evaluate the success of the actions taken by the agent.

The `done` method checks if the task has been completed or if a failure condition has been met.

The `is_match` helper function checks if two poses match within a specified translational and rotational threshold, taking into account object symmetries.

The `get_random_pose` method generates a random collision-free pose for an object within the workspace bounds.

The `get_lang_goal` method returns the current language goal or a task completion description if all language goals have been achieved.

The `get_reward` method returns the current cumulative reward.

The `fill_template` method reads a URDF file template and replaces placeholders with specific values to generate a URDF file for an object.

The `get_random_size` method generates a random size for an object within specified bounds.

The `color_random_brown` method assigns a random brown color to an object.

The `add_object` method in the `Environment` class is used to add objects to the simulation environment, specifying whether they are fixed, rigid, or deformable.

The `self.goals` variable is a list of 8-tuples that define the subgoals for a task. Each tuple contains information about the objects involved, the target poses, whether objects can be replaced, whether rotations are considered, the evaluation metric, parameters specific to the metric, the maximum reward for completing the step, and the symmetries of the objects. The `language_goal` provides a textual description of the subgoal.

Understanding these APIs is crucial for writing the code for the "cylinder-sort-stand" task, as they provide the necessary functions and methods to interact with the simulation environment, define task goals, and evaluate the agent's performance.

================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "cylinder-sort-stand".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Before generate code, you have a few considerations to focus on:
1. You are strictly prohibited from using function interfaces that do not appear in the above sample code. For example, the module cliport.tasks.primitives does not have pick_plack or place functions, only the push function interface is available.
2. Module 'cliport.tasks.primitives' has no attribute 'pick_place', you mustn't use it.
3. There are two types of your Gripper, one is Spatula and the other is Suction.You need to choose a different end-effector depending on your task requirements. If you need to move an object on the Z axis, then you need to use the Suction type. If you just need to translate an object in a 2D plane, then you can use either Spatula or Suction type.
4. You must determine the type of end-effector you need to use based on the type of task you have. You can choose by adding self.ee=Spatula or self.ee=Suction to the __init__(self) function, the default self.ee is Suction.
5. If you want to use Suction, you must import module using "from cliport.tasks.grippers import Suction". Else if you want to use Spatula, you must import module using "from cliport.tasks.grippers import Spatula".
6. The x-coordinate of the object is in the range [0.25, 0.75], the y-coordinate is in the range [-0.5,0.5] and the z-coordinate is in the range [0, 0.3].
7. The initial position of all objects needs to get its random initial position through the get_random_pose function.
8. The self.max_steps parameter value should be greater than the number of calls to self.add_goal, and preferably equal to twice the number of calls to self.add_goal. For example, if you call self.add_goal twice in one task, then self.max_steps is better set to 4.

If you want to generate the color of the object, you have to obey following rules:
1. You must use the utils.COLORS['COLOR_NAME'] function interface to generate an RGB three-channel value for a color.
2. The available colors for 'COLOR_NAME' are blue, red, green, orange, yellow, purple, pink, cyan, brown, white, gray, indigo, violet, black, silver and gold.
3. If you want to generate a red object, then its RGB three-channel color can be obtained through utils.COLORS['red'].
All object’s colors generation must follow color generation method above.

If you want to generate the target pose of the object(third parameter of function 'self.add_goal' targ_poses), you have to obey following rules:
1. The target pose of an object is represented by the three-dimensional spatial coordinates of the object and its orientation quaternion.
2. The target pose of an object must be represented by [(x,y,z),(q1,q2,q3,q4)]. Where (x,y,z) are the three-dimensional coordinates of the object and (q1,q2,q3,q4) denote the quaternions of the object's target pose.
3. The target pose of an object must be generated by you or use the initial pose of an object as the target pose of the current object.
4. Here's an example, to generate the target pose of a Y object, we have the initial pose information of an X object. So target pose of Y can be represented by pose_y=[(x,y,z),(q1,q2,q3,q4)] or pose_y=initial_pose_x.(Where x,y,z,q1,q2,q3,q4 are specific values.)
5. targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation).
6. The targ_poses you generate must contain translation[x,y,z], but rotation[q0,q1,q2,q3] you may or may not generate.
All object's target pose generation must follow method above.

Now write the code for the task "cylinder-sort-stand" in python code block starting with ```python.  Reminder: {'task-name': 'cylinder-sort-stand', 'task-description': "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.", 'assets-used': ['zone/zone.urdf', 'stacking/stand.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
from cliport.tasks.grippers import Suction

class CylinderSortStand(Task):
    """
    Sort colored cylinders by placing them onto matching colored stands within a defined zone,
    testing the robot's precision and object recognition capabilities.
    """

    def __init__(self):
        super().__init__()
        self.max_steps = 4  # We expect to call self.add_goal twice, so we set this to twice that number
        self.lang_template = "place the {color} cylinder on the {color} stand"
        self.task_completed_desc = "done sorting cylinders."
        self.ee = Suction  # We need to move objects on the Z axis, so we use the Suction end-effector

    def reset(self, env):
        super().reset(env)

        # Define the number of cylinders and stands
        n_cylinders = 2

        # Add goal zone
        zone_size = (0.12, 0.12, 0)  # Size of the zone
        zone_pose = self.get_random_pose(env, zone_size)  # Random pose within workspace bounds
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Define cylinder and stand sizes
        cylinder_size = (0.04, 0.04, 0.1)  # Diameter and height for the cylinder
        stand_size = (0.05, 0.05, 0.02)  # Size of the stand

        # Define colors for cylinders and stands
        colors = ['red', 'green']
        cylinder_colors = [utils.COLORS[color] for color in colors]
        stand_colors = [utils.COLORS[color] for color in colors]

        # Add cylinders and stands
        cylinders = []
        stands = []
        cylinder_template = 'cylinder/cylinder-template.urdf'
        stand_urdf = 'stacking/stand.urdf'
        for i in range(n_cylinders):
            # Add cylinder
            cylinder_pose = self.get_random_pose(env, cylinder_size)
            replace = {'COLOR': cylinder_colors[i]}
            cylinder_urdf = self.fill_template(cylinder_template, replace)
            cylinder_id = env.add_object(cylinder_urdf, cylinder_pose)
            cylinders.append(cylinder_id)

            # Add stand
            stand_pose = self.get_random_pose(env, stand_size)
            stand_id = env.add_object(stand_urdf, stand_pose, color=stand_colors[i])
            stands.append(stand_pose)  # We store the pose for the goal

            # Define the language goal
            language_goal = self.lang_template.format(color=colors[i])

            # Add goal for placing the cylinder on the stand
            self.add_goal(objs=[cylinder_id], matches=np.ones((1, 1)), targ_poses=[stand_pose],
                          replace=False, rotations=True, metric='pose', params=None,
                          step_max_reward=1, language_goal=language_goal)

        # Set the number of steps to twice the number of goals
        self.max_steps = len(cylinders) * 2
```

This code defines a task where the robot must sort colored cylinders by placing them onto matching colored stands within a defined zone. The task uses suction as the end-effector to move the cylinders vertically onto the stands. The `reset` method adds a goal zone, cylinders, and stands to the environment, and defines goals for placing each cylinder on a stand with the same color. The `add_goal` method is called with the appropriate parameters to set the goals for the task, including the language goal for each action. The `max_steps` is set to twice the number of cylinders to allow for enough steps to complete the task.

================= TRIAL: 1

================= Code Reflect!

>>> Prompt: 


Do you think your task is sufficently interesting to be added as a new task for future task given that we already have the following task name and descriptions? Moreover, does the simulation code achieve the goal and the language descriptions in the task? Be as rigorous and high-standard as possible.

Reminder:
your task:
{'task-name': 'cylinder-sort-stand', 'task-description': "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.", 'assets-used': ['zone/zone.urdf', 'stacking/stand.urdf', 'cylinder/cylinder-template.urdf']}

import numpy as np
import os
import pybullet as p
import random
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
from cliport.tasks.grippers import Suction

class CylinderSortStand(Task):
    """
    Sort colored cylinders by placing them onto matching colored stands within a defined zone,
    testing the robot's precision and object recognition capabilities.
    """

    def __init__(self):
        super().__init__()
        self.max_steps = 4  # We expect to call self.add_goal twice, so we set this to twice that number
        self.lang_template = "place the {color} cylinder on the {color} stand"
        self.task_completed_desc = "done sorting cylinders."
        self.ee = Suction  # We need to move objects on the Z axis, so we use the Suction end-effector

    def reset(self, env):
        super().reset(env)

        # Define the number of cylinders and stands
        n_cylinders = 2

        # Add goal zone
        zone_size = (0.12, 0.12, 0)  # Size of the zone
        zone_pose = self.get_random_pose(env, zone_size)  # Random pose within workspace bounds
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Define cylinder and stand sizes
        cylinder_size = (0.04, 0.04, 0.1)  # Diameter and height for the cylinder
        stand_size = (0.05, 0.05, 0.02)  # Size of the stand

        # Define colors for cylinders and stands
        colors = ['red', 'green']
        cylinder_colors = [utils.COLORS[color] for color in colors]
        stand_colors = [utils.COLORS[color] for color in colors]

        # Add cylinders and stands
        cylinders = []
        stands = []
        cylinder_template = 'cylinder/cylinder-template.urdf'
        stand_urdf = 'stacking/stand.urdf'
        for i in range(n_cylinders):
            # Add cylinder
            cylinder_pose = self.get_random_pose(env, cylinder_size)
            replace = {'COLOR': cylinder_colors[i]}
            cylinder_urdf = self.fill_template(cylinder_template, replace)
            cylinder_id = env.add_object(cylinder_urdf, cylinder_pose)
            cylinders.append(cylinder_id)

            # Add stand
            stand_pose = self.get_random_pose(env, stand_size)
            stand_id = env.add_object(stand_urdf, stand_pose, color=stand_colors[i])
            stands.append(stand_pose)  # We store the pose for the goal

            # Define the language goal
            language_goal = self.lang_template.format(color=colors[i])

            # Add goal for placing the cylinder on the stand
            self.add_goal(objs=[cylinder_id], matches=np.ones((1, 1)), targ_poses=[stand_pose],
                          replace=False, rotations=True, metric='pose', params=None,
                          step_max_reward=1, language_goal=language_goal)

        # Set the number of steps to twice the number of goals
        self.max_steps = len(cylinders) * 2

current task list:
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}




=========
Reply explain your reasons and then say True or False, formatted in a python dictionary, do not miss commas or add extra spaces. Here are some examples.

{
	"task_name": "sort-color-blocks",
	"task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "yellow-bowl.urdf", "box/box-template.urdf],
	"reasons": "not interesting because it overlaps with the current task `put-block-in-bowl`"
	"add_to_the_task_list": "False",
}

{
  	"task-name": "guided-ball-maze",
  	"task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
  	"assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
   	"reasons": "the language descriptions are too ambiguous. Navigation is also hard to complete."
  	"add_to_the_task_list": "False",  
}

{
 	"task-name": "sort-blocks-by-zone",
 	"task-description": "Sort different colored blocks into their corresponding colored zones marked on the tabletop.",
 	"assets-used": ["zone/zone.urdf", "stacking/block.urdf"],
	"reasons": "the task is not covered in the current list and is an interesting combination of zone and block objects." 
	"add_to_the_task_list": "True",
}

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
    "reasons": "this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere.", 
    "add_to_the_task_list": "False",
}

{
    "task-name": "arrange-blocks-on-pallet",
    "task-description": "arrange the blocks on the pallet in the order: red, orange, yellow, green, blue, and purple.",
    "assets-used": ["stacking/block.urdf", "pallet/pallelt.urdf"],
    "reasons": "this task overlaps with `arrange-boxes-on-pallet` by merely changing the blocks to boxes.", 
    "add_to_the_task_list": "False",
}

{
    "task-name": "cylinder-color-alignment",
    "task-description": "Pick up cylinders of different colors and align them inside a box in the order of the colors displayed on the single green line on the tabletop.",
    "assets-used": ["cylinder/cylinder-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf   
    "reasons": "the execution code only has one goal, i.e. it will only move one cylinder on top of the box, which is not that interesting.", 
    "add_to_the_task_list": "False","]
}

{
    "task-name": "build-bridge",
    "task-description": "Construct a bridge using two yellow blocks and three blue blocks. Firstly, place the two yellow blocks on each of the two bases parallel to each other with a fair amount of space in between. Then, place the blue block horizontally on top of the yellow blocks.",
     "assets-used": ["block/block.urdf", "ball/ball-template.urdf"]
    "reasons": "this task is an interesting and long-horizon task for pick and place primitives. Training manipulation agent with this skill will be a useful building block for next skills.", 
    "add_to_the_task_list": "True",
}

=========

Please incorporate these feedbacks when you design new task!



>>> Answer: 
{
    "task-name": "cylinder-sort-stand",
    "task-description": "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.",
    "assets-used": ["zone/zone.urdf", "stacking/stand.urdf", "cylinder/cylinder-template.urdf"],
    "reasons": "The task is sufficiently different from the existing tasks, focusing on precision placement and color matching with cylindrical objects, which is not covered by the current tasks. However, the simulation code provided does not compile due to missing imports and possibly undefined methods such as 'get_random_pose' and 'fill_template'. Also, the language descriptions are clear and directly related to the task goals, but the code does not check if the cylinders are sorted correctly in the post-conditions, which is necessary for task completion validation.",
    "add_to_the_task_list": "False",
}

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}
- cylinder_sort_stand: {'task-name': 'cylinder-sort-stand', 'task-description': "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.", 'assets-used': ['zone/zone.urdf', 'stacking/stand.urdf', 'cylinder/cylinder-template.urdf']}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
Based on the guidelines provided and the assets available, here's a description of a new task:

```python
{
    "task-name": "bowl-cylinder-stacking",
    "task-description": "Stack a specific number of colored cylinders into a bowl without toppling them, testing the robot's precision and stability control.",
    "assets-used": ["bowl/bowl.urdf", "cylinder/cylinder-template.urdf"]
}
```

This task is novel as it involves stacking objects (cylinders) of a specific shape into another object (a bowl) which has an inherent instability due to the curved shape of the bowl. The challenge lies in carefully placing each cylinder to avoid knocking over the existing stack, requiring a high level of precision and control. The task also involves the challenge of object recognition (differentiating cylinder colors) and spatial reasoning (understanding and planning the stack within the confines of the bowl).

================= API Preview!

>>> Prompt: 
Before writing the code for the task "bowl-cylinder-stacking". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
I understand the provided APIs and the structure of the `Task` class, which serves as a base class for defining robotic tasks in a simulated environment. Here's a summary of the key components and the `self.goals` variable:

### Key Components of the `Task` Class:
- **Initialization**: Sets up the end effector, mode, six degrees of freedom (DoF) capability, primitive actions, camera configurations, and workspace bounds.
- **Reset**: Resets the task state and goals.
- **Oracle**: Provides an oracle agent that can generate expert actions for the current state.
- **Reward Function**: Calculates the reward based on the current state and the task's goals.
- **Done**: Checks if the task is completed or has failed.
- **Environment Helper Functions**: Includes functions to check if poses match, get random collision-free poses, and other utility functions.
- **Helper Functions**: Includes functions to fill templates with data, get random sizes for objects, and apply random colors.

### Environment Class:
- **add_object**: Adds an object to the environment with a specified pose and category.

### `self.goals` Variable:
The `self.goals` variable is a list of 8-tuples, each representing a subgoal in a multi-step task. Each tuple contains the following elements:

1. **objs (List of obj_id)**: A list of object IDs that are involved in the current subgoal.
2. **matches (Binary Matrix)**: A binary matrix indicating potential matches between objects and target poses. The dimensions are `len(objs)` by `len(targs)`.
3. **targ_poses (List of Poses)**: A list of target poses, each defined by a translation (x, y, z) and a rotation quaternion (q0, q1, q2, q3).
4. **replace (Boolean)**: Indicates whether objects can match with multiple targets (`True`) or if they must match uniquely (`False`).
5. **rotations (Boolean)**: Specifies whether the placement action includes a rotational degree of freedom.
6. **metric (`pose` or `zone`)**: The metric used to evaluate the task, either by matching poses or by placing objects within a specified zone.
7. **params (List of (zone_target, zone_size))**: Parameters for each zone, including the target pose and size, if the metric is `zone`.
8. **step_max_reward (float)**: The maximum reward for completing the current subgoal.
9. **symmetries**: The radians of rotational symmetry around the z-axis for the objects.
10. **language_goal**: A string providing a low-level language instruction describing the goal of the current step.

The task's success is determined by the agent's ability to match objects to their target poses or zones according to the specified goals, while adhering to the constraints of the environment, such as avoiding collisions and staying within the workspace bounds. The reward function and completion check are based on the progress made towards these goals.

================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "bowl-cylinder-stacking".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Before generate code, you have a few considerations to focus on:
1. You are strictly prohibited from using function interfaces that do not appear in the above sample code. For example, the module cliport.tasks.primitives does not have pick_plack or place functions, only the push function interface is available.
2. Module 'cliport.tasks.primitives' has no attribute 'pick_place', you mustn't use it.
3. There are two types of your Gripper, one is Spatula and the other is Suction.You need to choose a different end-effector depending on your task requirements. If you need to move an object on the Z axis, then you need to use the Suction type. If you just need to translate an object in a 2D plane, then you can use either Spatula or Suction type.
4. You must determine the type of end-effector you need to use based on the type of task you have. You can choose by adding self.ee=Spatula or self.ee=Suction to the __init__(self) function, the default self.ee is Suction.
5. If you want to use Suction, you must import module using "from cliport.tasks.grippers import Suction". Else if you want to use Spatula, you must import module using "from cliport.tasks.grippers import Spatula".
6. The x-coordinate of the object is in the range [0.25, 0.75], the y-coordinate is in the range [-0.5,0.5] and the z-coordinate is in the range [0, 0.3].
7. The initial position of all objects needs to get its random initial position through the get_random_pose function.
8. The self.max_steps parameter value should be greater than the number of calls to self.add_goal, and preferably equal to twice the number of calls to self.add_goal. For example, if you call self.add_goal twice in one task, then self.max_steps is better set to 4.

If you want to generate the color of the object, you have to obey following rules:
1. You must use the utils.COLORS['COLOR_NAME'] function interface to generate an RGB three-channel value for a color.
2. The available colors for 'COLOR_NAME' are blue, red, green, orange, yellow, purple, pink, cyan, brown, white, gray, indigo, violet, black, silver and gold.
3. If you want to generate a red object, then its RGB three-channel color can be obtained through utils.COLORS['red'].
All object’s colors generation must follow color generation method above.

If you want to generate the target pose of the object(third parameter of function 'self.add_goal' targ_poses), you have to obey following rules:
1. The target pose of an object is represented by the three-dimensional spatial coordinates of the object and its orientation quaternion.
2. The target pose of an object must be represented by [(x,y,z),(q1,q2,q3,q4)]. Where (x,y,z) are the three-dimensional coordinates of the object and (q1,q2,q3,q4) denote the quaternions of the object's target pose.
3. The target pose of an object must be generated by you or use the initial pose of an object as the target pose of the current object.
4. Here's an example, to generate the target pose of a Y object, we have the initial pose information of an X object. So target pose of Y can be represented by pose_y=[(x,y,z),(q1,q2,q3,q4)] or pose_y=initial_pose_x.(Where x,y,z,q1,q2,q3,q4 are specific values.)
5. targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation).
6. The targ_poses you generate must contain translation[x,y,z], but rotation[q0,q1,q2,q3] you may or may not generate.
All object's target pose generation must follow method above.

Now write the code for the task "bowl-cylinder-stacking" in python code block starting with ```python.  Reminder: {'task-name': 'bowl-cylinder-stacking', 'task-description': "Stack a specific number of colored cylinders into a bowl without toppling them, testing the robot's precision and stability control.", 'assets-used': ['bowl/bowl.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
from cliport.tasks.grippers import Suction

class BowlCylinderStacking(Task):
    """
    Stack a specific number of colored cylinders into a bowl without toppling them,
    testing the robot's precision and stability control.
    """

    def __init__(self):
        super().__init__()
        self.max_steps = 10  # Assuming we will call self.add_goal 5 times
        self.lang_template = "stack {num} {color} cylinders in the {bowl_color} bowl"
        self.task_completed_desc = "done stacking cylinders."
        self.ee = Suction  # Using Suction end-effector for vertical stacking
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Define the number of cylinders to stack and their size
        n_cylinders = np.random.randint(1, 4)  # Random number of cylinders between 1 and 3
        cylinder_size = (0.05, 0.05, 0.1)  # Diameter and height for the cylinder

        # Define the bowl size and add the bowl to the environment
        bowl_size = (0.15, 0.15, 0.05)  # Diameter and height for the bowl
        bowl_pose = self.get_random_pose(env, bowl_size)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_id = env.add_object(bowl_urdf, bowl_pose, 'fixed')
        bowl_color = 'brown'  # Color for the bowl

        # Add cylinders to the environment
        cylinder_template = 'cylinder/cylinder-template.urdf'
        cylinder_color = 'red'  # Color for the cylinders
        cylinders = []
        for _ in range(n_cylinders):
            # Get a random pose for the cylinder
            cylinder_pose = self.get_random_pose(env, cylinder_size)
            # Fill the URDF template with the cylinder size and color
            replace = {'SIZE': cylinder_size, 'COLOR': utils.COLORS[cylinder_color]}
            cylinder_urdf = self.fill_template(cylinder_template, replace)
            # Add the cylinder to the environment
            cylinder_id = env.add_object(cylinder_urdf, cylinder_pose)
            cylinders.append(cylinder_id)

        # Define the target pose for the cylinders to be stacked in the bowl
        # The target pose is the same as the bowl's pose but with an adjusted z-coordinate
        # to account for the height of the stacked cylinders
        targ_poses = [(bowl_pose[0], bowl_pose[1])]  # We use the bowl's pose for all cylinders

        # Add the goal for stacking the cylinders
        # Since we want to stack all cylinders in the same bowl, we use the same target pose
        # and set replace to False to indicate that each cylinder must go to a unique pose
        self.add_goal(objs=cylinders, matches=np.ones((n_cylinders, 1)), targ_poses=targ_poses,
                      replace=False, rotations=False, metric='pose', params=None,
                      step_max_reward=1, language_goal=self.lang_template.format(
                          num=n_cylinders, color=cylinder_color, bowl_color=bowl_color))

        # Note: We set rotations to False because we don't need to consider the rotation of the cylinders
        # when stacking them in the bowl. We also set step_max_reward to 1 since we have only one goal.
```

This code defines a task where the robot must stack a random number of red cylinders into a brown bowl. The `BowlCylinderStacking` class inherits from the `Task` class and sets up the task environment by adding a bowl and a specific number of cylinders to the environment. The cylinders are to be stacked in the bowl, and the goal is defined accordingly. The `Suction` end-effector is used for precise vertical stacking. The target pose for the cylinders is based on the bowl's pose, and the `add_goal` method is used to define the task's objective. The language template provides a description of the task for language-conditioned policies.

================= TRIAL: 2

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}
- cylinder_sort_stand: {'task-name': 'cylinder-sort-stand', 'task-description': "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.", 'assets-used': ['zone/zone.urdf', 'stacking/stand.urdf', 'cylinder/cylinder-template.urdf']}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
Here is a description of a new robot simulation task that adheres to the provided constraints and guidelines:

```python
{
    "task-name": "bowl-cylinder-arrangement",
    "task-description": "Arrange a set of colored cylinders in a specific pattern inside a large bowl without any overlap between the cylinders, testing the robot's dexterity and spatial reasoning.",
    "assets-used": ["bowl/bowl.urdf", "cylinder/cylinder-template.urdf"]
}
```

### Novelty and Challenges:

- **Novelty**: This task requires arranging multiple objects (cylinders) inside a container (bowl) in a specified pattern. It differs from stacking or simply placing objects in a bowl as it requires precise control to avoid overlaps and maintain the pattern.
- **Challenges**:
  - **Dexterity**: The robot must manipulate the cylinders with precision to arrange them without causing them to fall over or touch each other.
  - **Spatial Reasoning**: The task tests the robot's ability to reason about space and to plan the placement of the cylinders to fit the given pattern.
  - **Color Recognition**: If the cylinders are colored, the robot would need to identify the colors and place them accordingly to match the pattern.
  - **Pattern Formation**: The task may involve complex patterns which require advanced planning and sequencing of movements.
  - **Collision Avoidance**: Ensuring that the cylinders do not collide with each other or the sides of the bowl adds to the complexity of the task.

The task remains physically feasible and adheres to the principles of physics, as it involves picking, placing, and arranging solid objects within a defined space.

================= API Preview!

>>> Prompt: 
Before writing the code for the task "bowl-cylinder-arrangement". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
I understand the provided APIs and the structure of the `Task` class, which serves as a base class for defining robot simulation tasks. Here's a summary of the key components and the `self.goals` variable:

### Key Components of the `Task` Class:

- **Initialization**: The constructor initializes various attributes such as the end effector type (`ee`), the mode of operation, whether the task allows six degrees of freedom (`sixdof`), the primitive used for manipulation, and the camera configuration.
- **Reset**: The `reset` method is called to reset the task environment. It initializes goals, language goals, progress, and rewards.
- **Oracle**: The `oracle` method provides an oracle agent that can calculate the optimal action based on perfect knowledge of the environment.
- **Reward**: The `reward` method calculates the reward for the current timestep based on the task's goals and the current state of the environment.
- **Done**: The `done` method checks if the task is completed or has failed.
- **Environment Helper Functions**: These include methods like `is_match` to check if two poses match within a threshold, `get_random_pose` to get a random collision-free pose, and `get_lang_goal` to get the current language goal.
- **Helper Functions**: These include utility functions like `fill_template` to read and replace strings in a file, `get_random_size` to get a random object size, and `color_random_brown` to change the color of an object.

### The `self.goals` Variable:

The `self.goals` variable is a list of 8-tuples, each representing a subgoal in a multi-step pick-and-place task. Each tuple contains the following elements:

1. **objs**: A list of object IDs that are involved in the current subgoal.
2. **matches**: A binary matrix indicating which objects are matched with which target poses. The dimensions of the matrix are `len(objs)` by `len(targs)`.
3. **targ_poses**: A list of target poses, where each pose is a tuple of translation (x, y, z) and rotation (quaternion q0, q1, q2, q3).
4. **replace**: A boolean indicating whether each object can match with only one unique target (`False`) or multiple targets (`True`).
5. **rotations**: A boolean indicating whether the placement action includes a rotational degree of freedom.
6. **metric**: A string that specifies the evaluation metric for the subgoal, which can be either 'pose' for precise placement or 'zone' for placing within a general area.
7. **params**: A list of parameters relevant to the metric, such as zone targets and sizes if the metric is 'zone'.
8. **step_max_reward**: A float representing the total reward for completing the subgoal, independent of the number of objects but dependent on the number of goals.
9. **symmetries**: The radians of rotational symmetry around the z-axis for the objects.
10. **language_goal**: A string providing low-level language instructions that describe the goal of the current step.

### Environment Class:

The `add_object` method in the environment class is used to add objects to the simulation. It takes the URDF file path, the pose of the object, and the category (fixed, rigid, or deformable) as arguments and returns the object ID.

The objects in the task must obey physics and avoid collisions. The goal poses for the objects must be within the specified workspace bounds, and the task involves multiple subgoals that the agent must complete using pick-and-place primitives.

================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "bowl-cylinder-arrangement".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Before generate code, you have a few considerations to focus on:
1. You are strictly prohibited from using function interfaces that do not appear in the above sample code. For example, the module cliport.tasks.primitives does not have pick_plack or place functions, only the push function interface is available.
2. Module 'cliport.tasks.primitives' has no attribute 'pick_place', you mustn't use it.
3. There are two types of your Gripper, one is Spatula and the other is Suction.You need to choose a different end-effector depending on your task requirements. If you need to move an object on the Z axis, then you need to use the Suction type. If you just need to translate an object in a 2D plane, then you can use either Spatula or Suction type.
4. You must determine the type of end-effector you need to use based on the type of task you have. You can choose by adding self.ee=Spatula or self.ee=Suction to the __init__(self) function, the default self.ee is Suction.
5. If you want to use Suction, you must import module using "from cliport.tasks.grippers import Suction". Else if you want to use Spatula, you must import module using "from cliport.tasks.grippers import Spatula".
6. The x-coordinate of the object is in the range [0.25, 0.75], the y-coordinate is in the range [-0.5,0.5] and the z-coordinate is in the range [0, 0.3].
7. The initial position of all objects needs to get its random initial position through the get_random_pose function.
8. The self.max_steps parameter value should be greater than the number of calls to self.add_goal, and preferably equal to twice the number of calls to self.add_goal. For example, if you call self.add_goal twice in one task, then self.max_steps is better set to 4.

If you want to generate the color of the object, you have to obey following rules:
1. You must use the utils.COLORS['COLOR_NAME'] function interface to generate an RGB three-channel value for a color.
2. The available colors for 'COLOR_NAME' are blue, red, green, orange, yellow, purple, pink, cyan, brown, white, gray, indigo, violet, black, silver and gold.
3. If you want to generate a red object, then its RGB three-channel color can be obtained through utils.COLORS['red'].
All object’s colors generation must follow color generation method above.

If you want to generate the target pose of the object(third parameter of function 'self.add_goal' targ_poses), you have to obey following rules:
1. The target pose of an object is represented by the three-dimensional spatial coordinates of the object and its orientation quaternion.
2. The target pose of an object must be represented by [(x,y,z),(q1,q2,q3,q4)]. Where (x,y,z) are the three-dimensional coordinates of the object and (q1,q2,q3,q4) denote the quaternions of the object's target pose.
3. The target pose of an object must be generated by you or use the initial pose of an object as the target pose of the current object.
4. Here's an example, to generate the target pose of a Y object, we have the initial pose information of an X object. So target pose of Y can be represented by pose_y=[(x,y,z),(q1,q2,q3,q4)] or pose_y=initial_pose_x.(Where x,y,z,q1,q2,q3,q4 are specific values.)
5. targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation).
6. The targ_poses you generate must contain translation[x,y,z], but rotation[q0,q1,q2,q3] you may or may not generate.
All object's target pose generation must follow method above.

Now write the code for the task "bowl-cylinder-arrangement" in python code block starting with ```python.  Reminder: {'task-name': 'bowl-cylinder-arrangement', 'task-description': "Arrange a set of colored cylinders in a specific pattern inside a large bowl without any overlap between the cylinders, testing the robot's dexterity and spatial reasoning.", 'assets-used': ['bowl/bowl.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
from cliport.tasks.grippers import Suction

class BowlCylinderArrangement(Task):
    """
    Arrange a set of colored cylinders in a specific pattern inside a large bowl
    without any overlap between the cylinders, testing the robot's dexterity and
    spatial reasoning.
    """

    def __init__(self):
        super().__init__()
        self.max_steps = 10  # Assuming we will have 5 cylinders to arrange
        self.lang_template = "put the {color} cylinder in the bowl"
        self.task_completed_desc = "done arranging the cylinders."
        self.ee = Suction  # Using Suction end-effector for vertical movement

    def reset(self, env):
        super().reset(env)

        # Define the number of cylinders to arrange
        n_cylinders = 5

        # Add a large bowl to the environment
        bowl_size = (0.18, 0.18, 0.06)  # Size of the bowl (x, y, z)
        bowl_pose = self.get_random_pose(env, bowl_size)  # Random pose for the bowl
        bowl_urdf = 'bowl/bowl.urdf'
        env.add_object(bowl_urdf, bowl_pose, 'fixed')  # Add bowl as a fixed object

        # Define cylinder properties
        cylinder_template = 'cylinder/cylinder-template.urdf'
        cylinder_size = (0.05, 0.05, 0.1)  # Size of the cylinder (x, y, z)
        cylinder_colors = ['red', 'green', 'blue', 'yellow', 'purple']  # Cylinder colors

        # Add cylinders to the environment
        cylinders = []
        for i in range(n_cylinders):
            # Get a random pose for the cylinder
            cylinder_pose = self.get_random_pose(env, cylinder_size)
            # Get the color for the cylinder
            color_name = cylinder_colors[i]
            color_rgb = utils.COLORS[color_name]
            # Fill in the template URDF with the specific color
            replace = {'COLOR': color_rgb}
            cylinder_urdf = self.fill_template(cylinder_template, replace)
            # Add the cylinder to the environment
            cylinder_id = env.add_object(cylinder_urdf, cylinder_pose)
            cylinders.append(cylinder_id)

            # Define the language goal for placing this cylinder
            language_goal = self.lang_template.format(color=color_name)

            # Add the goal for this cylinder
            self.add_goal(
                objs=[cylinder_id],  # The current cylinder
                matches=np.int32([[1]]),  # Match with one target pose
                targ_poses=[bowl_pose],  # Target pose is the bowl pose
                replace=True,  # Cylinders can overlap in the bowl
                rotations=False,  # No need to match rotations
                metric='zone',  # The goal is to be within the bowl zone
                params=[(bowl_pose, bowl_size)],  # Parameters for the zone
                step_max_reward=1 / n_cylinders,  # Reward for placing this cylinder
                language_goal=language_goal  # Language goal
            )
```

================= TRIAL: 3

================= Task and Asset Design!

>>> Prompt: 
You are an AI in robot simulation code and task design. I will provide you some example tasks, code implementation, and some guidelines for how to generate tasks and then you will help me generate a new task. My goal is to design diverse and feasible tasks for tabletop manipulation. I will first ask you to describe the task in natural languages and then will let you write the code for it. 

=========
Here are all the assets. Use only these assets in the task and code design. 
"""
insertion/:
ell.urdf  fixture.urdf

bowl/:
bowl.urdf

box/:
box-template.urdf

stacking/:
block.urdf  stand.urdf

zone/:
zone.obj  zone.urdf

pallet/:
pallet.obj  pallet.urdf

ball/:
ball-template.urdf

cylinder/:
cylinder-template.urdf

bowl/:
bowl.urdf

# assets not for picking
corner/:
corner-template.urdf

line/:
single-green-line-template.urdf

container/:
container-template.urdf
"""
 
=========
Here are some examples of good tasks. Try to learn from these structures but avoid overlapping wiht them.

{"assets-used": ["zone/zone.urdf", "block/small.urdf"],
 "task-description": "Push piles of small objects into a target goal zone marked on the tabletop.",
 "task-name": "sweeping-piles"}

{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "Place all blocks of a specified color in a bowl of specified color.",
 "task-name": "put-block-in-bowl"}
 
{"assets-used": ["insertion/ell.urdf", "insertion/fixture.urdf"],
 "task-description": "pick up the L-shaped red block and place it into the L-shaped fixture.",
 "task-name": "block-insertion"}
 
{"assets-used": ["kitting/kit.urdf", "kitting/object-template.urdf"],
 "task-description": "pick up different objects and arrange them on a board marked with corresponding silhouettes.",
 "task-name": "assembling-kits"}
 
{"assets-used": ["pallet/pallet.urdf", "box/box-template.urdf"],
 "task-description": "pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.",
 "task-name": "palletizing-boxes"}
 
{"assets-used": ["stacking/stand.urdf", "stacking/block.urdf"],
 "task-description": "sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.",
 "task-name": "stack-block-pyramid"}
 
{"assets-used": ["container/container-template.urdf", "box/box-template.urdf"],
 "task-description": "pick up randomly sized boxes and place them tightly into a container.",
 "task-name": "packing-boxes"}
 
{"assets-used": ["bowl/bowl.urdf", "stacking/block.urdf"],
 "task-description": "pick up the red blocks and place them into the green bowls amidst other objects.",
 "task-name": "place-red-in-green"}
 
{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

{"assets-used": ["box/box-template.urdf", "corner/corner-template.urdf"],
 "task-description": "pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..",
 "task-name": "align-box-corner"}

=========
Here are some tasks that you have come up with before. Try to learn from these structures but avoid overlapping with these tasks. For instance, `bowl_ball_placement` and `sort_balls_in_bowls` are the same task. `pile_boxes_in_corner` and `stack_blocks_into_pallet` are similar tasks, `align-cylinder-in-corner` and `align-cylinder-corner` are similar.
- sweeping-piles: {'assets-used': ['zone/zone.urdf', 'block/small.urdf'], 'task-description': 'push piles of small objects into a target goal zone marked on the tabletop.', 'task-name': 'sweeping-piles'}
- place-red-in-green: {'assets-used': ['bowl/bowl.urdf', 'stacking/block.urdf'], 'task-description': 'pick up the red blocks and place them into the green bowls amidst other objects.', 'task-name': 'place-red-in-green'}
- align-box-corner: {'assets-used': ['box/box-template.urdf', 'corner/corner-template.urdf'], 'task-description': 'pick up the randomly sized box and align one of its corners to the L-shaped marker on the tabletop..', 'task-name': 'align-box-corner'}
- stack-block-pyramid: {'assets-used': ['stacking/stand.urdf', 'stacking/block.urdf'], 'task-description': 'sequentially stack 6 blocks into a pyramid of 3-2-1 with rainbow colored ordering.', 'task-name': 'stack-block-pyramid'}
- palletizing-boxes: {'assets-used': ['pallet/pallet.urdf', 'box/box-template.urdf'], 'task-description': 'pick up homogeneous fixed-sized boxes and stack them in transposed layers on the pallet.', 'task-name': 'palletizing-boxes'}
- assembling-kits: {'assets-used': ['kitting/kit.urdf', 'kitting/object-template.urdf'], 'task-description': 'pick up different objects and arrange them on a board marked with corresponding silhouettes.', 'task-name': 'assembling-kits'}
- packing-boxes: {'assets-used': ['container/container-template.urdf', 'box/box-template.urdf'], 'task-description': 'pick up randomly sized boxes and place them tightly into a container.', 'task-name': 'packing-boxes'}
- manipulating-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'rearrange a deformable rope such that it connects the two endpoints of a 3-sided square.', 'task-name': 'manipulating-rope'}
- align-rope: {'assets-used': ['square/square-template.urdf'], 'task-description': 'manipulate a deformable rope to connect its end-points between two corners of a 3-sided square.', 'task-name': 'align-rope'}
- cylinder_sort_stand: {'task-name': 'cylinder-sort-stand', 'task-description': "Sort colored cylinders by placing them onto matching colored stands within a defined zone, testing the robot's precision and object recognition capabilities.", 'assets-used': ['zone/zone.urdf', 'stacking/stand.urdf', 'cylinder/cylinder-template.urdf']}





=========
Here are some bad example task instances with explanations.
{
    "task_name": "sort-color-blocks",
    "task_descriptions": "Pick up differently colored blocks and place them into separate bowls of matching color."
    "assets-used": ["bowl.urdf", "box/box-template.urdf],
}
reasons: not interesting because it overlaps with the current task `put-block-in-bowl`.

{
    "task-name": "guided-ball-maze",
    "task-description": "Navigate a small ball through a maze by tilting the maze board to reach the target zone.",
    "assets-used": ["zone-template.urdf", "square-template.urdf", "ball.urdf", "maze.urdf"],
}
reasons: the language descriptions are too ambiguous. Navigation is also hard to complete. Also maze.urf does not exist.

{
    "task-name": "insert_cylinder_in_sphere",
    "task-description": "Pick up the cylinder and insert it into the sphere with an opening on top.",
    "assets-used": ["cylinder/cylinder-template.urdf", "sphere/sphere-template.urdf"],
}
reasons: this task does not make sense. The sphere does not have an opening on top, and you cannot insert a cylinder into a sphere. Similarly tasks like `insert-ball-into-cylinder` and `cylinder-box-insertion` are invalid.

{
    "task-name": "ball-box-obstacle-course",
    "task-description": "Navigate a ball through an obstacle course created by randomly placed boxes and finally place it inside a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: Navigate the ball is not related to tabletop manipulation tasks.

{
    "task-name": "ball-in-box",
    "task-description": "Use a cable to guide a ball into an open box.",
    "assets-used": ["cable/cable.urdf", "ball/ball-template.urdf", "box/box-template.urdf"]
}
reasons: This task is too hard since it involves interaction of the cable and the ball and cannot be easily completed.

{
    "task-name": "ball-in-container",
    "task-description": "Use the spatula to lift a ball over a wall of boxes and drop it into a container.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "container/container-template.urdf"]
}
reasons: The only action primitives as pick and place. One cannot use a spatula to lift an object.

{
    "task-name": "line-ball-sorting",
    "task-description": "Move balls of different colors along a single green line, placing each ball in a designated colored box at the end of the line. The challenge includes precision in maintaining the ball on the line and the correct identification of the box color corresponding to each ball.",
    "assets-used": ["ball/ball-template.urdf", "box/box-template.urdf", "line/single-green-line-template.urdf"]
}
reasons: Piling or stacking balls are physically infeasible in the simulation.



=========
Now please describe the new task in natural languages and explain its novelty and challenges. Format the answer in a python dictionary with keys "task-name" and value type string, "task-description" (one specific sentence) and value type string, and "assets-used" and value type list of strings. Note that

- Do not use assets that are not in the list above. 
- Tasks that have more colors and shapes are interesting.
- Be as specific as possible about the number, shape, and color of each asset in the task descriptions. 
- The task need to obey physics and remain feasible.





>>> Answer: 
Here is the description of a new tabletop manipulation task that adheres to the provided guidelines and leverages the available assets:

```python
{
    "task-name": "cylinder-placement-sequence",
    "task-description": "Arrange a sequence of colored cylinders on matching colored zones on the tabletop, following a specific order from smallest to largest diameter.",
    "assets-used": ["zone/zone.urdf", "cylinder/cylinder-template.urdf"]
}
```

Explanation of Novelty and Challenges:
- This task introduces the challenge of size discrimination in addition to color matching, requiring the robot to recognize and handle cylinders of different diameters.
- The task requires sequential task completion, with the robot needing to place the cylinders in a predefined order, enhancing its planning capabilities.
- As the cylinders vary in size, the grasping and placement strategy will need to adapt to each cylinder's diameter, testing the robot's manipulation skills.
- The use of colored zones adds to the complexity by requiring the robot to not only identify the correct cylinder but also the corresponding colored zone on the tabletop.

================= API Preview!

>>> Prompt: 
Before writing the code for the task "cylinder-placement-sequence". Here are some APIs that are defined. Please confirm that you understand these APIs.

"""
class Task():
    """Base Task class."""

    def __init__(self):
        self.ee = Suction
        self.mode = 'train'
        self.sixdof = False
        self.primitive = primitives.PickPlace()
        self.oracle_cams = cameras.Oracle.CONFIG

        # Evaluation epsilons (for pose evaluation metric).
        self.pos_eps = 0.01
        self.rot_eps = np.deg2rad(15)

        # Workspace bounds.
        self.pix_size = 0.003125
        self.bounds = np.array([[0.25, 0.75], [-0.5, 0.5], [0, 0.3]])
        self.zone_bounds = np.copy(self.bounds)

        self.goals = []
        self.lang_goals = []
        self.task_completed_desc = "task completed."
        self.progress = 0
        self._rewards = 0
        self.assets_root = None

    def reset(self, env):
        if not self.assets_root:
            raise ValueError('assets_root must be set for task, '
                             'call set_assets_root().')
        self.goals = []
        self.lang_goals = []
        self.progress = 0  # Task progression metric in range [0, 1].
        self._rewards = 0  # Cumulative returned rewards.

    # -------------------------------------------------------------------------
    # Oracle Agent
    # -------------------------------------------------------------------------

    def oracle(self, env):
        """Oracle agent."""
        OracleAgent = collections.namedtuple('OracleAgent', ['act'])

        def act(obs, info):
            """Calculate action."""

            # Oracle uses perfect RGB-D orthographic images and segmentation masks.
            _, hmap, obj_mask = self.get_true_image(env)

            # Unpack next goal step.
            objs, matches, targs, replace, rotations, _, _, _ = self.goals[0]

            # Match objects to targets without replacement.
            if not replace:

                # Modify a copy of the match matrix.
                matches = matches.copy()

                # Ignore already matched objects.
                for i in range(len(objs)):
                    object_id, (symmetry, _) = objs[i]
                    pose = p.getBasePositionAndOrientation(object_id)
                    targets_i = np.argwhere(matches[i, :]).reshape(-1)
                    for j in targets_i:
                        if self.is_match(pose, targs[j], symmetry):
                            matches[i, :] = 0
                            matches[:, j] = 0

            # Get objects to be picked (prioritize farthest from nearest neighbor).
            nn_dists = []
            nn_targets = []
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                xyz, _ = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                if len(targets_i) > 0:
                    targets_xyz = np.float32([targs[j][0] for j in targets_i])
                    dists = np.linalg.norm(
                        targets_xyz - np.float32(xyz).reshape(1, 3), axis=1)
                    nn = np.argmin(dists)
                    nn_dists.append(dists[nn])
                    nn_targets.append(targets_i[nn])

                # Handle ignored objects.
                else:
                    nn_dists.append(0)
                    nn_targets.append(-1)
            order = np.argsort(nn_dists)[::-1]

            # Filter out matched objects.
            order = [i for i in order if nn_dists[i] > 0]

            pick_mask = None
            for pick_i in order:
                pick_mask = np.uint8(obj_mask == objs[pick_i][0])

                # Erode to avoid picking on edges.
                # pick_mask = cv2.erode(pick_mask, np.ones((3, 3), np.uint8))

                if np.sum(pick_mask) > 0:
                    break

            # Trigger task reset if no object is visible.
            if pick_mask is None or np.sum(pick_mask) == 0:
                self.goals = []
                self.lang_goals = []
                print('Object for pick is not visible. Skipping demonstration.')
                return

            # Get picking pose.
            pick_prob = np.float32(pick_mask)
            pick_pix = utils.sample_distribution(pick_prob)
            # For "deterministic" demonstrations on insertion-easy, use this:
            # pick_pix = (160,80)
            pick_pos = utils.pix_to_xyz(pick_pix, hmap,
                                        self.bounds, self.pix_size)
            pick_pose = (np.asarray(pick_pos), np.asarray((0, 0, 0, 1)))

            # Get placing pose.
            targ_pose = targs[nn_targets[pick_i]]
            obj_pose = p.getBasePositionAndOrientation(objs[pick_i][0])
            if not self.sixdof:
                obj_euler = utils.quatXYZW_to_eulerXYZ(obj_pose[1])
                obj_quat = utils.eulerXYZ_to_quatXYZW((0, 0, obj_euler[2]))
                obj_pose = (obj_pose[0], obj_quat)
            world_to_pick = utils.invert(pick_pose)
            obj_to_pick = utils.multiply(world_to_pick, obj_pose)
            pick_to_obj = utils.invert(obj_to_pick)
            place_pose = utils.multiply(targ_pose, pick_to_obj)

            # Rotate end effector?
            if not rotations:
                place_pose = (place_pose[0], (0, 0, 0, 1))

            place_pose = (np.asarray(place_pose[0]), np.asarray(place_pose[1]))

            return {'pose0': pick_pose, 'pose1': place_pose}

        return OracleAgent(act)

    # -------------------------------------------------------------------------
    # Reward Function and Task Completion Metrics
    # -------------------------------------------------------------------------

    def reward(self):
        """Get delta rewards for current timestep.

        Returns:
          A tuple consisting of the scalar (delta) reward, plus `extras`
            dict which has extra task-dependent info from the process of
            computing rewards that gives us finer-grained details. Use
            `extras` for further data analysis.
        """
        reward, info = 0, {}

        # Unpack next goal step.
        objs, matches, targs, _, _, metric, params, max_reward = self.goals[0]

        # Evaluate by matching object poses.
        if metric == 'pose':
            step_reward = 0
            for i in range(len(objs)):
                object_id, (symmetry, _) = objs[i]
                pose = p.getBasePositionAndOrientation(object_id)
                targets_i = np.argwhere(matches[i, :]).reshape(-1)
                for j in targets_i:
                    target_pose = targs[j]
                    if self.is_match(pose, target_pose, symmetry):
                        step_reward += max_reward / len(objs)
                        print(f"object {i} match with target {j} rew: {step_reward}")
                        break

        # Evaluate by measuring object intersection with zone.
        elif metric == 'zone':
            zone_pts, total_pts = 0, 0
            obj_pts, zones = params
            for zone_idx, (zone_pose, zone_size) in enumerate(zones):

                # Count valid points in zone.
                for obj_idx, obj_id in enumerate(obj_pts):
                    pts = obj_pts[obj_id]
                    obj_pose = p.getBasePositionAndOrientation(obj_id)
                    world_to_zone = utils.invert(zone_pose)
                    obj_to_zone = utils.multiply(world_to_zone, obj_pose)
                    pts = np.float32(utils.apply(obj_to_zone, pts))
                    if len(zone_size) > 1:
                        valid_pts = np.logical_and.reduce([
                            pts[0, :] > -zone_size[0] / 2, pts[0, :] < zone_size[0] / 2,
                            pts[1, :] > -zone_size[1] / 2, pts[1, :] < zone_size[1] / 2,
                            pts[2, :] < self.zone_bounds[2, 1]])

                    # if zone_idx == matches[obj_idx].argmax():
                    zone_pts += np.sum(np.float32(valid_pts))
                    total_pts += pts.shape[1]
            step_reward = max_reward * (zone_pts / total_pts)

        # Get cumulative rewards and return delta.
        reward = self.progress + step_reward - self._rewards
        self._rewards = self.progress + step_reward

        # Move to next goal step if current goal step is complete.
        if np.abs(max_reward - step_reward) < 0.01:
            self.progress += max_reward  # Update task progress.
            self.goals.pop(0)
            if len(self.lang_goals) > 0:
                self.lang_goals.pop(0)

        return reward, info

    def done(self):
        """Check if the task is done or has failed.

        Returns:
          True if the episode should be considered a success, which we
            use for measuring successes, which is particularly helpful for tasks
            where one may get successes on the very last time step, e.g., getting
            the cloth coverage threshold on the last alllowed action.
            However, for bag-items-easy and bag-items-hard (which use the
            'bag-items' metric), it may be necessary to filter out demos that did
            not attain sufficiently high reward in external code. Currently, this
            is done in `main.py` and its ignore_this_demo() method.
        """
        return (len(self.goals) == 0) or (self._rewards > 0.99)
        # return zone_done or defs_done or goal_done

    # -------------------------------------------------------------------------
    # Environment Helper Functions
    # -------------------------------------------------------------------------

    def is_match(self, pose0, pose1, symmetry):
        """Check if pose0 and pose1 match within a threshold."""

        # Get translational error.
        diff_pos = np.float32(pose0[0][:2]) - np.float32(pose1[0][:2])
        dist_pos = np.linalg.norm(diff_pos)

        # Get rotational error around z-axis (account for symmetries).
        diff_rot = 0
        if symmetry > 0:
            rot0 = np.array(utils.quatXYZW_to_eulerXYZ(pose0[1]))[2]
            rot1 = np.array(utils.quatXYZW_to_eulerXYZ(pose1[1]))[2]
            diff_rot = np.abs(rot0 - rot1) % symmetry
            if diff_rot > (symmetry / 2):
                diff_rot = symmetry - diff_rot

        return (dist_pos < self.pos_eps) and (diff_rot < self.rot_eps)

    def get_random_pose(self, env, obj_size):
        """Get random collision-free object pose within workspace bounds."""

        # Get erosion size of object in pixels.
        max_size = np.sqrt(obj_size[0] ** 2 + obj_size[1] ** 2)
        erode_size = int(np.round(max_size / self.pix_size))

        _, hmap, obj_mask = self.get_true_image(env)

        # Randomly sample an object pose within free-space pixels.
        free = np.ones(obj_mask.shape, dtype=np.uint8)
        for obj_ids in env.obj_ids.values():
            for obj_id in obj_ids:
                free[obj_mask == obj_id] = 0
        free[0, :], free[:, 0], free[-1, :], free[:, -1] = 0, 0, 0, 0
        free = cv2.erode(free, np.ones((erode_size, erode_size), np.uint8))

        # if np.sum(free) == 0:
        #     return None, None

        if np.sum(free) == 0:
            # avoid returning None, None
            # return None, None
            pix = (obj_mask.shape[0] // 2, obj_mask.shape[1] // 2)
        else:
            pix = utils.sample_distribution(np.float32(free))
        pos = utils.pix_to_xyz(pix, hmap, self.bounds, self.pix_size)
        pos = (pos[0], pos[1], obj_size[2] / 2)
        theta = np.random.rand() * 2 * np.pi
        rot = utils.eulerXYZ_to_quatXYZW((0, 0, theta))
        return pos, rot

    def get_lang_goal(self):
        if len(self.lang_goals) == 0:
            return self.task_completed_desc
        else:
            return self.lang_goals[0]

    def get_reward(self):
        return float(self._rewards)

    # -------------------------------------------------------------------------
    # Helper Functions
    # -------------------------------------------------------------------------

    def fill_template(self, template, replace):
        """Read a file and replace key strings."""
        full_template_path = os.path.join(self.assets_root, template)
        with open(full_template_path, 'r') as file:
            fdata = file.read()
        for field in replace:
            for i in range(len(replace[field])):
                fdata = fdata.replace(f'{field}{i}', str(replace[field][i]))
        alphabet = string.ascii_lowercase + string.digits
        rname = ''.join(random.choices(alphabet, k=16))
        tmpdir = tempfile.gettempdir()
        template_filename = os.path.split(template)[-1]
        fname = os.path.join(tmpdir, f'{template_filename}.{rname}')
        with open(fname, 'w') as file:
            file.write(fdata)
        return fname

    def get_random_size(self, min_x, max_x, min_y, max_y, min_z, max_z):
        """Get random box size."""
        size = np.random.rand(3)
        size[0] = size[0] * (max_x - min_x) + min_x
        size[1] = size[1] * (max_y - min_y) + min_y
        size[2] = size[2] * (max_z - min_z) + min_z
        return tuple(size)

    def color_random_brown(self, obj):
        shade = np.random.rand() + 0.5
        color = np.float32([shade * 156, shade * 117, shade * 95, 255]) / 255
        p.changeVisualShape(obj, -1, rgbaColor=color)

  """""
  
  # Environment Class
  def add_object(self, urdf, pose, category='rigid'):
    """List of (fixed, rigid, or deformable) objects in env."""
    fixed_base = 1 if category == 'fixed' else 0
    obj_id = pybullet_utils.load_urdf(
        p,
        os.path.join(self.assets_root, urdf),
        pose[0],
        pose[1],
        useFixedBase=fixed_base)
    self.obj_ids[category].append(obj_id)
    return obj_id
"""

=========
Note that the objects need to obey physics and not collide with each other, and the object goal poses need to be above the table with lower bound x=0.25, y=-0.5 and upper bound x=0.75, y=0.5. When there are multiple objects for a multi-step pick-and-place task, there are often multiple subgoals. Once the task and environment are generated, an agent with a pick and place primitive will follow the defined goal to accomplish the tasks. 

Additionally, make sure you understand and summarize the ``self.goals`` variables, which has a list of 8-tuple with (objs, matches, targ_poses, replace, rotations, metric, params, step_max_reward, symmetries).
- objs (List of obj_id): object ID.
- matches (Binary Matrix): a binary matrix that denotes which object is matched with which target. This matrix has dimension len(objs) x len(targs).
- targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation). 
- replace (Boolean): whether each object can match with one unique target. This is important if we have one target and multiple objects. If it's set to be false, then any object matching with the target will satisfy.
- rotations (Boolean): whether the placement action has a rotation degree of freedom. 
- metric (`pose` or `zone`): `pose` or `zone` that the object needs to be transported to. Example: `pose`. 
- params (List of (zone_target, zone_size)): a list of (zone_target, zone_size) for each zone if the metric is `zone`. 
- step_max_reward (float): the total reward of matching all the objects with all the target poses. It is not dependent on the number of objects but dependent on the number of goals. 
- symmetries: the radians that the object is symmetric around z axis.
- language_goal: the low-level language instructions that denote the goal of this step.
 


>>> Answer: 
I understand the provided APIs and the structure of the `Task` class, as well as the `add_object` method for the environment class. Here's a summary of my understanding:

The `Task` class is a base class for defining robotic tasks. It initializes with default parameters for the end effector, mode, six degrees of freedom (DoF) flag, a pick-and-place primitive, and oracle camera configurations. It also sets up evaluation metrics for pose accuracy, workspace bounds, and initializes variables for goals, language goals, progress, rewards, and the assets root directory.

The `reset` method is used to reset the task, clearing goals and progress. The `oracle` method provides an oracle agent that can generate actions based on perfect knowledge of the environment, which is useful for demonstrations or testing.

The `reward` method calculates the reward for the current timestep based on the task's goals and the current state of the environment. It uses either pose matching or zone intersection to evaluate the task's progress.

The `done` method checks if the task is completed or has failed, which is determined by whether all goals have been achieved or if the cumulative rewards exceed a certain threshold.

The `is_match` method checks if two poses match within a specified translational and rotational threshold, taking into account any symmetries of the object around the z-axis.

The `get_random_pose` method generates a random collision-free pose for an object within the workspace bounds.

The `get_lang_goal` method returns the current language goal, and `get_reward` returns the current cumulative reward.

The `fill_template` method is a utility for reading a URDF file template and replacing placeholders with specific values.

The `get_random_size` method generates a random size for an object within specified bounds, and `color_random_brown` applies a random brown color to an object.

The `add_object` method in the environment class is used to add objects to the simulation, specifying their URDF file, pose, and whether they are fixed, rigid, or deformable.

The `self.goals` variable is a list of 8-tuples that define the subgoals for a task. Each tuple contains information about the objects involved in the subgoal, how they match with target poses, whether objects can be replaced, whether rotations are considered, the evaluation metric, parameters specific to the metric, the maximum reward for completing the subgoal, and the symmetries of the objects.

Understanding these APIs and the structure of the `Task` class is crucial for implementing the "cylinder-placement-sequence" task, as it will involve defining the goals, setting up the environment, and calculating rewards based on the task's objectives.

================= Code Generation!

>>> Prompt: 
Now I will provide you some reference code and you can write the code for the task "cylinder-placement-sequence".


"""
import os

import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils


class PackingShapes(Task):
    """pick up randomly sized shapes and place them tightly into a container."""

    def __init__(self):
        super().__init__()
        self.max_steps = 1
        self.homogeneous = False

        self.lang_template = "pack the {obj} in the brown box"
        self.task_completed_desc = "done packing shapes."
        self.additional_reset()


    def reset(self, env):
        super().reset(env)

        # Shape Names:
        shapes = utils.assembling_kit_shapes

        n_objects = 5
        if self.mode == 'train':
            obj_shapes = np.random.choice(self.train_set, n_objects, replace=False)
        else:
            if self.homogeneous:
                obj_shapes = [np.random.choice(self.test_set, replace=False)] * n_objects
            else:
                obj_shapes = np.random.choice(self.test_set, n_objects, replace=False)

        # Shuffle colors to avoid always picking an object of the same color
        colors, color_names = utils.get_colors(mode=self.mode)

        # Add container box.
        zone_size = self.get_random_size(0.1, 0.15, 0.1, 0.15, 0.05, 0.05)
        zone_pose = self.get_random_pose(env, zone_size)
        container_template = 'container/container-template.urdf'
        replace = {'DIM': zone_size, 'HALF': (zone_size[0] / 2, zone_size[1] / 2, zone_size[2] / 2)}
        # IMPORTANT: REPLACE THE TEMPLATE URDF with `fill_template`
        container_urdf = self.fill_template(container_template, replace)
        env.add_object(container_urdf, zone_pose, 'fixed')

        # Add objects.
        objects = []
        template = 'kitting/object-template.urdf'
        for i in range(n_objects):
            shape = obj_shapes[i]

            # x, y, z dimensions for the asset size
            size = (0.08, 0.08, 0.02)
            pose= self.get_random_pose(env, size)
            fname = f'{shape:02d}.obj'
            fname = os.path.join(self.assets_root, 'kitting', fname)
            scale = [0.003, 0.003, 0.001]  # .0005
            replace = {'FNAME': (fname,),
                       'SCALE': scale,
                       'COLOR': colors[i]}

            # IMPORTANT: REPLACE THE TEMPLATE URDF
            urdf = self.fill_template(template, replace)
            block_id = env.add_object(urdf, pose)
            objects.append(block_id)

        # Pick the first shape.
        num_objects_to_pick = 1
        for i in range(num_objects_to_pick):
            # IMPORTANT: Specify (obj_pts, [(zone_pose, zone_size)]) for target `zone`. obj_pts is a dict
            language_goal = self.lang_template.format(obj=shapes[obj_shapes[i]])
            self.add_goal(objs=[objects[i]], matches=np.int32([[1]]), targ_poses=[zone_pose], replace=False,
                rotations=True, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1 / num_objects_to_pick,
                language_goal=language_goal)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p


class PlaceRedInGreen(Task):
    """pick up the red blocks and place them into the green bowls amidst other objects."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10
        self.lang_template = "put the red blocks in a green bowl"
        self.task_completed_desc = "done placing blocks in bowls."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)
        n_bowls = np.random.randint(1, 4)
        n_blocks = np.random.randint(1, n_bowls + 1)

        # Add bowls.
        # x, y, z dimensions for the asset size
        bowl_size = (0.12, 0.12, 0)
        bowl_urdf = 'bowl/bowl.urdf'
        bowl_poses = []
        for _ in range(n_bowls):
            bowl_pose = self.get_random_pose(env, obj_size=bowl_size)
            env.add_object(urdf=bowl_urdf, pose=bowl_pose, category='fixed')
            bowl_poses.append(bowl_pose)

        # Add blocks.
        # x, y, z dimensions for the asset size
        blocks = []
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'
        for _ in range(n_blocks):
            block_pose = self.get_random_pose(env, obj_size=block_size)
            block_id = env.add_object(block_urdf, block_pose)
            blocks.append(block_id)

        # Goal: each red block is in a different green bowl.
        self.add_goal(objs=blocks, matches=np.ones((len(blocks), len(bowl_poses))), targ_poses=bowl_poses, replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1, language_goal=self.lang_template)

        # Colors of distractor objects.
        bowl_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'green']
        block_colors = [utils.COLORS[c] for c in utils.COLORS if c != 'red']

        # Add distractors.
        n_distractors = 0
        while n_distractors < 6:
            is_block = np.random.rand() > 0.5
            urdf = block_urdf if is_block else bowl_urdf
            size = block_size if is_block else bowl_size
            colors = block_colors if is_block else bowl_colors
            pose = self.get_random_pose(env, obj_size=size)
            color = colors[n_distractors % len(colors)]

            obj_id = env.add_object(urdf, pose, color=color)
            n_distractors += 1
"""
"""
import numpy as np
from cliport.tasks import primitives
from cliport.tasks.grippers import Spatula
from cliport.tasks.task import Task
from cliport.utils import utils


class SweepingPiles(Task):
    """Push piles of small objects into a target goal zone marked on the tabletop."""

    def __init__(self):
        super().__init__()
        self.max_steps = 20
        self.lang_template = "push the pile of blocks into the green square"
        self.task_completed_desc = "done sweeping."
        self.primitive = primitives.push
        self.ee = Spatula
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add goal zone.
        zone_size = (0.12, 0.12, 0)
        zone_pose = self.get_random_pose(env, zone_size)
        env.add_object('zone/zone.urdf', zone_pose, 'fixed')

        # Add pile of small blocks with `make_piles` function
        obj_ids = self.make_piles(env)

        # Add goal
        self.add_goal(objs=obj_ids, matches=np.ones((50, 1)), targ_poses=[zone_pose], replace=True,
                rotations=False, metric='zone', params=[(zone_pose, zone_size)], step_max_reward=1, language_goal=self.lang_template)
"""
"""
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
import pybullet as p

class StackBlockPyramid(Task):
    """Build a pyramid of colored blocks in a color sequence"""

    def __init__(self):
        super().__init__()
        self.max_steps = 12
        self.lang_template = "make the {row} row with {blocks}"
        self.task_completed_desc = "done stacking block pyramid."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Add base.
        base_size = (0.05, 0.15, 0.005)
        base_urdf = 'stacking/stand.urdf'
        base_pose = self.get_random_pose(env, base_size)
        env.add_object(base_urdf, base_pose, category='fixed')

        # Block colors.
        colors = [
            utils.COLORS['purple'], utils.COLORS['blue'], utils.COLORS['green'],
            utils.COLORS['yellow'], utils.COLORS['orange'], utils.COLORS['red']
        ]

        # Add blocks.
        block_size = (0.04, 0.04, 0.04)
        block_urdf = 'stacking/block.urdf'

        objs = []
        for i in range(6):
            block_pose = self.get_random_pose(env, block_size)
            block_id = env.add_object(block_urdf, block_pose, color=colors[i])
            objs.append(block_id)

        # IMPORTANT Associate placement locations for goals.
        place_pos = [(0, -0.05, 0.03), (0, 0, 0.03),
                     (0, 0.05, 0.03), (0, -0.025, 0.08),
                     (0, 0.025, 0.08), (0, 0, 0.13)]
        targs = [(utils.apply(base_pose, i), base_pose[1]) for i in place_pos]

        # Goal: blocks are stacked in a pyramid (bottom row: green, blue, purple).
        language_goal = self.lang_template.format(blocks="the green, blue and purple blocks", row="bottom")
        self.add_goal(objs=objs[:3], matches=np.ones((3, 3)), targ_poses=targs[:3], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 2, symmetries=[np.pi/2]*3, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (middle row: yellow, orange).
        language_goal = self.lang_template.format(blocks="the yellow and orange blocks", row="middle")      
        self.add_goal(objs=objs[3:5], matches=np.ones((2, 2)), targ_poses=targs[3:5], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 3, symmetries=[np.pi/2]*2, language_goal=language_goal)

        # Goal: blocks are stacked in a pyramid (top row: red).
        language_goal = self.lang_template.format(blocks="the red block", row="top")
        self.add_goal(objs=objs[5:], matches=np.ones((1, 1)), targ_poses=targs[5:], replace=False,
                rotations=True, metric='pose', params=None, step_max_reward=1 / 6, symmetries=[np.pi/2]*1, language_goal=language_goal)
"""



Do not use libraries, functions, and assets that you don't know. For each object, try to describe its color, size, category in the task first before you write the code. You do not need extra helper functions. Comment the code liberally to explain what each piece does and why it's written that way. If you have only one goal, `step_max_reward` in `add_goal` should be 1. Use functions `make_piles` and `make_ropes` for creating piles and cables. To use spatula together with the push primitives, import the libraries 
"""
from cliport.tasks import primitives;
from cliport.tasks.grippers import Spatula
"""
and then use `self.primitive = primitives.push` and `self.ee = Spatula`.
Note that the number of language goals usually match the number of motion goals, since they should correspond to each other.

Before generate code, you have a few considerations to focus on:
1. You are strictly prohibited from using function interfaces that do not appear in the above sample code. For example, the module cliport.tasks.primitives does not have pick_plack or place functions, only the push function interface is available.
2. Module 'cliport.tasks.primitives' has no attribute 'pick_place', you mustn't use it.
3. There are two types of your Gripper, one is Spatula and the other is Suction.You need to choose a different end-effector depending on your task requirements. If you need to move an object on the Z axis, then you need to use the Suction type. If you just need to translate an object in a 2D plane, then you can use either Spatula or Suction type.
4. You must determine the type of end-effector you need to use based on the type of task you have. You can choose by adding self.ee=Spatula or self.ee=Suction to the __init__(self) function, the default self.ee is Suction.
5. If you want to use Suction, you must import module using "from cliport.tasks.grippers import Suction". Else if you want to use Spatula, you must import module using "from cliport.tasks.grippers import Spatula".
6. The x-coordinate of the object is in the range [0.25, 0.75], the y-coordinate is in the range [-0.5,0.5] and the z-coordinate is in the range [0, 0.3].
7. The initial position of all objects needs to get its random initial position through the get_random_pose function.
8. The self.max_steps parameter value should be greater than the number of calls to self.add_goal, and preferably equal to twice the number of calls to self.add_goal. For example, if you call self.add_goal twice in one task, then self.max_steps is better set to 4.

If you want to generate the color of the object, you have to obey following rules:
1. You must use the utils.COLORS['COLOR_NAME'] function interface to generate an RGB three-channel value for a color.
2. The available colors for 'COLOR_NAME' are blue, red, green, orange, yellow, purple, pink, cyan, brown, white, gray, indigo, violet, black, silver and gold.
3. If you want to generate a red object, then its RGB three-channel color can be obtained through utils.COLORS['red'].
All object’s colors generation must follow color generation method above.

If you want to generate the target pose of the object(third parameter of function 'self.add_goal' targ_poses), you have to obey following rules:
1. The target pose of an object is represented by the three-dimensional spatial coordinates of the object and its orientation quaternion.
2. The target pose of an object must be represented by [(x,y,z),(q1,q2,q3,q4)]. Where (x,y,z) are the three-dimensional coordinates of the object and (q1,q2,q3,q4) denote the quaternions of the object's target pose.
3. The target pose of an object must be generated by you or use the initial pose of an object as the target pose of the current object.
4. Here's an example, to generate the target pose of a Y object, we have the initial pose information of an X object. So target pose of Y can be represented by pose_y=[(x,y,z),(q1,q2,q3,q4)] or pose_y=initial_pose_x.(Where x,y,z,q1,q2,q3,q4 are specific values.)
5. targ_poses (List of Poses [(translation [x,y,z], rotation [q0,q1,q2,q3])] ): a list of target poses of tuple (translation, rotation).
6. The targ_poses you generate must contain translation[x,y,z], but rotation[q0,q1,q2,q3] you may or may not generate.
All object's target pose generation must follow method above.

Now write the code for the task "cylinder-placement-sequence" in python code block starting with ```python.  Reminder: {'task-name': 'cylinder-placement-sequence', 'task-description': 'Arrange a sequence of colored cylinders on matching colored zones on the tabletop, following a specific order from smallest to largest diameter.', 'assets-used': ['zone/zone.urdf', 'cylinder/cylinder-template.urdf']} 


>>> Answer: 
```python
import numpy as np
from cliport.tasks.task import Task
from cliport.utils import utils
from cliport.tasks.grippers import Suction

class CylinderPlacementSequence(Task):
    """Arrange a sequence of colored cylinders on matching colored zones on the tabletop, following a specific order from smallest to largest diameter."""

    def __init__(self):
        super().__init__()
        self.max_steps = 10  # Assuming we have 5 cylinders to place, 2 steps per cylinder
        self.ee = Suction  # Suction end-effector is needed to lift cylinders
        self.lang_template = "place the {color} cylinder on the {color} zone"
        self.task_completed_desc = "done placing all cylinders in sequence."
        self.additional_reset()

    def reset(self, env):
        super().reset(env)

        # Define the number of cylinders and their sizes
        n_cylinders = 5
        diameters = np.linspace(0.02, 0.10, n_cylinders)  # Smallest to largest diameters

        # Define colors for cylinders and zones
        colors = ['red', 'green', 'blue', 'yellow', 'purple']
        np.random.shuffle(colors)  # Shuffle colors to randomize cylinder order

        # Add zones with matching colors to cylinders
        zone_size = (0.12, 0.12, 0)  # Zones are flat squares on the table
        zone_urdf = 'zone/zone.urdf'
        zone_poses = []
        for i in range(n_cylinders):
            zone_pose = self.get_random_pose(env, zone_size)
            env.add_object(zone_urdf, zone_pose, 'fixed', color=utils.COLORS[colors[i]])
            zone_poses.append(zone_pose)

        # Add cylinders with corresponding colors and sizes
        cylinder_template = 'cylinder/cylinder-template.urdf'
        cylinders = []
        for i in range(n_cylinders):
            size = (diameters[i], diameters[i], 0.15)  # Height is constant, diameter varies
            pose = self.get_random_pose(env, size)
            replace = {'DIM': size, 'HALF': (size[0] / 2, size[1] / 2, size[2] / 2)}
            color = utils.COLORS[colors[i]]
            # Replace the template URDF with the specific size and color
            cylinder_urdf = self.fill_template(cylinder_template, replace)
            cylinder_id = env.add_object(cylinder_urdf, pose, color=color)
            cylinders.append(cylinder_id)

        # Add goals for placing cylinders on matching zones
        for i in range(n_cylinders):
            language_goal = self.lang_template.format(color=colors[i])
            self.add_goal(objs=[cylinders[i]], matches=np.int32([[1]]), targ_poses=[zone_poses[i]],
                          replace=False, rotations=True, metric='pose', params=None,
                          step_max_reward=1/n_cylinders, language_goal=language_goal)

# Note: The task assumes that the zones and cylinders are matched by index after shuffling.
# The cylinders are placed in increasing order of diameter, and the zones are placed randomly on the table.
# The Suction end-effector is used to pick up the cylinders, and the task is completed when all cylinders are placed correctly.
```

================= TRIAL: 4